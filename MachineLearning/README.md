# MachineLearning
Welcome to my quilt of knowledge pertaining to Machine Learning. I am going to be walking through basic ML concepts and move into neural networks. \
https://machinelearningmastery.com/start-here/

## Python

## d3

## Keras

### Keras Optimizers:
Keras provides APIs for various implementations of Optimizers. You will find the following types of optimizers in Keras â€“ \
SGD \
RMSprop \
Adam \
Adadelta \
Adagrad \
Adamax \
Nadam \
Ftrl \
https://machinelearningknowledge.ai/keras-optimizers-explained-with-examples-for-beginners/

### L2 Regularization
Keras provides a weight regularization API that allows you to add a penalty for weight size to the loss function. \
https://machinelearningmastery.com/how-to-reduce-overfitting-in-deep-learning-with-weight-regularization/

### Dropout Regularization
When created, the dropout rate can be specified to the layer as the probability of setting each input to the layer to zero. This is different from the definition of dropout rate from the papers, in which the rate refers to the probability of retaining an input. \
https://machinelearningmastery.com/how-to-reduce-overfitting-with-dropout-regularization-in-keras/

### Data Augmentation
Training deep learning neural network models on more data can result in more skillful models, and the augmentation techniques can create variations of the images that can improve the ability of the fit models to generalize what they have learned to new images. \
The Keras deep learning neural network library provides the capability to fit models using image data augmentation via the ImageDataGenerator class. \
https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/

## Tensorflow

### Deep Playground
Deep playground is an interactive visualization of neural networks, written in TypeScript using d3.js. \
https://github.com/tensorflow/playground

### Tensorboard
TensorBoard is a suite of web applications for inspecting and understanding your TensorFlow runs and graphs. \
https://github.com/tensorflow/tensorboard

## Convolutional Neural Networks

### Pooling Layers
A pooling layer is a new layer added after the convolutional layer. Specifically, after a nonlinearity (e.g. ReLU) has been applied to the feature maps output by a convolutional layer; for example the layers in a model may look as follows: \
https://machinelearningmastery.com/pooling-layers-for-convolutional-neural-networks/ 

### Overfitting and Early Stopping
When training a large network, there will be a point during training when the model will stop generalizing and start learning the statistical noise in the training dataset. \
https://machinelearningmastery.com/early-stopping-to-avoid-overtraining-neural-network-models/


